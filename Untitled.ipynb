{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76cb4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\lenovo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing dependencies of pyodbc: Invalid version: '4.0.0-unsupported'\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\lenovo\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\lenovo\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 483, in run\n",
      "    installed_versions[distribution.canonical_name] = distribution.version\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\pip\\_internal\\metadata\\pkg_resources.py\", line 192, in version\n",
      "    return parse_version(self._dist.version)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 56, in parse\n",
      "    return Version(version)\n",
      "  File \"C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\packaging\\version.py\", line 202, in __init__\n",
      "    raise InvalidVersion(f\"Invalid version: '{version}'\")\n",
      "pip._vendor.packaging.version.InvalidVersion: Invalid version: '4.0.0-unsupported'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.43.4-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: torch in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.4-cp39-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (1.9)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Downloading transformers-4.43.4-py3-none-any.whl (9.4 MB)\n",
      "   ---------------------------------------- 9.4/9.4 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.4-cp39-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745642a13a1d41e0ac240bb3626040ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Lenovo\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fea2b9740142e1bf868e1ea9840f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c9a9c8a60d4cb5a3ec08b7a7103c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4619a13a51404f87ac8e0ac1ab43ea46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf97ecc5a32405ba517e06d7f07b001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbea87688334193b205a4e8435e9c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04264265e4e4be7a8d3a9479a2ea7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, the world was a place of great beauty and great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great danger, and the world was a place of great danger. The world was a place of great\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(prompt, max_length=100):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "prompt = \"Once upon a time\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c40d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=100, temperature=0.7, top_k=50):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=max_length, temperature=temperature, top_k=top_k, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "193fd234",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a land of ancient magic and mysterious creatures, the world of the dead is a place of mystery and mystery.\n",
      "\n",
      "The world of the dead is a place of mystery and mystery.\n",
      "\n",
      "The world of the dead is a place of mystery and mystery.\n",
      "\n",
      "The world of the dead is a place of mystery and mystery.\n",
      "\n",
      "The world of the dead is a place of mystery and mystery.\n",
      "\n",
      "The world of the dead is a place of mystery and mystery.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In a land of ancient magic and mysterious creatures,\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c9aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=200, temperature=0.8, top_k=50):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=max_length, temperature=temperature, top_k=top_k, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d917094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a land where magic and mythical creatures are part of everyday life, the secrets of the underworld remain hidden from the eyes of the living.\n",
      "\n",
      "The story of the world of the underworld is told in the story of the four gods, the four gods of the underworld, and the four gods of the underworld.\n",
      "\n",
      "The story of the four gods is told in the story of the four gods, the four gods of the underworld, and the four gods of the underworld.\n",
      "\n",
      "The story of the four gods is told in the story of the four gods, the four gods of the underworld, and the four gods of the underworld.\n",
      "\n",
      "The story of the four gods is told in the story of the four gods, the four gods of the underworld, and the four gods of the underworld.\n",
      "\n",
      "The story of the four gods is told in the story of the four gods, the four gods of the underworld, and the four gods of the underworld.\n",
      "\n",
      "The story of\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In a land where magic and mythical creatures are part of everyday life, the secrets of the underworld remain hidden from the eyes of the living.\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb073e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=200, temperature=0.9, top_k=50):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs, max_length=max_length, temperature=temperature, top_k=top_k, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15a3508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a land where magic and mythical creatures coexist with humans, the underworld is shrouded in mystery. The ancient legends tell of four powerful gods who govern the realms beneath the earth, each ruling over a different aspect of the underworld. Their stories are intertwined with the fate of the living, as their secrets shape the world above.\n",
      "\n",
      "The story of the underworld is told in the form of a series of stories, each of which is told in a different way. The stories are told in the form of a series of stories, each of which is told in a different way. The stories are told in the form of a series of stories, each of which is told in a different way.\n",
      "\n",
      "The story of the underworld is told in the form of a series of stories, each of which is told in a different way. The stories are told in the form of a series of stories, each of which is told in a different way.\n",
      "\n",
      "The story of the underworld is told in\n"
     ]
    }
   ],
   "source": [
    "prompt = \"In a land where magic and mythical creatures coexist with humans, the underworld is shrouded in mystery. The ancient legends tell of four powerful gods who govern the realms beneath the earth, each ruling over a different aspect of the underworld. Their stories are intertwined with the fate of the living, as their secrets shape the world above.\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b59f5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt, max_length=300, temperature=0.9, top_k=50, top_p=0.95):\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "985d5a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:572: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of magic and mythical creatures, where humans and otherworldly beings coexist, the underworld remains a place of profound mystery. Ancient legends speak of four powerful deities who rule over different domains of the underworld. Each deity has a unique influence on both the living and the dead. Their intertwined fates are crucial to understanding the hidden forces shaping the world above.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell. The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is\n"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"In the realm of magic and mythical creatures, where humans and otherworldly beings coexist, \"\n",
    "    \"the underworld remains a place of profound mystery. Ancient legends speak of four powerful deities \"\n",
    "    \"who rule over different domains of the underworld. Each deity has a unique influence on both the living \"\n",
    "    \"and the dead. Their intertwined fates are crucial to understanding the hidden forces shaping the world above.\"\n",
    ")\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f40945db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of magic and mythical creatures, where humans and otherworldly beings coexist, the underworld remains a place of profound mystery. Ancient legends speak of four powerful deities who rule over different domains of the underworld. Each deity has a unique influence on both the living and the dead. Their intertwined fates are crucial to understanding the hidden forces shaping the world above.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell. The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is a place of great mystery and mystery. It is the place where the gods and goddesses of the underworld dwell.\n",
      "\n",
      "The Underworld is\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_redundancy(text):\n",
    "    # Example of a simple redundancy removal\n",
    "    return re.sub(r'(\\b\\w+\\b)\\s+\\1', r'\\1', text)\n",
    "\n",
    "generated_text = remove_redundancy(generated_text)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f59574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
